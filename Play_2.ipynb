{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "import jax\n",
    "from dataclasses import dataclass\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "\n",
    "#with install_import_hook(\"gpjax\", \"beartype.beartype\"):\n",
    "import gpjax as gpx\n",
    "from gpjax.distributions import GaussianDistribution\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "# plt.style.use(\n",
    "#     \"https://raw.githubusercontent.com/JaxGaussianProcesses/GPJax/main/docs/examples/gpjax.mplstyle\"\n",
    "# )\n",
    "# colors = rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "key = jr.PRNGKey(123)\n",
    "\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "tfd = tfp.distributions\n",
    "from gpjax.kernels.base import AdditiveKernel\n",
    "\n",
    "\n",
    "import optax as ox\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "\n",
    "\n",
    "\n",
    "from typing import List, Union, Callable\n",
    "from jaxtyping import Num, Float\n",
    "from gpjax.typing import Array, ScalarFloat\n",
    "from beartype.typing import Optional\n",
    "from gpjax.base import Module, param_field,static_field\n",
    "import cola\n",
    "from cola.linalg.decompositions.decompositions import Cholesky\n",
    "from jax import vmap\n",
    "\n",
    "\n",
    "# custom bits\n",
    "from gpjax.precip_gp import VerticalDataset, VerticalSmoother, ConjugatePrecipGP, ProblemInfo, VariationalPrecipGP\n",
    "from gpjax.normalizer import Normalizer\n",
    "from gpjax.plotting import plot_component, plot_data, plot_marginals, plot_interactions, plot_params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100_000 entries sampled across time/lat/lon over first day of data\n",
    "\n",
    "## X2D has:\n",
    "\n",
    "0\"Sea surface temperature (K)\"\n",
    "\n",
    "1\"Sensible heat flux (W/m^2)\"\n",
    "\n",
    "2\"Latent heat flux (W/m^2)\"\n",
    "\n",
    "3\"Vertically-integrated moisture convergence (kg/m^2)\"\n",
    "\n",
    "4\"Column relative humidity (%)\"\n",
    "\n",
    "\n",
    "## X3D has:\n",
    "\n",
    "0\"Absolute temperature (K)\"\n",
    "\n",
    "1\"Relative humidity (%)\"\n",
    "\n",
    "2\"Specific humidity (kg/kg)\"\n",
    "\n",
    "3\"Geopotential height (m^2 s^-2)\"\n",
    "\n",
    "4\"Zonal wind (m/s)\"\n",
    "\n",
    "5\"Meridional wind (m/s)\"\n",
    "\n",
    "6\"Potential temperature (K)\"\n",
    "\n",
    "7\"Equivalent potential temperature (K)\"\n",
    "\n",
    "8\"Equivalent potential temperature saturation deficit (K)\"\n",
    "\n",
    "9\"Saturated equivalent potential temperature (K)\"\n",
    "\n",
    "10\"MSE-conserving plume buoyancy (m/s^2)\"\n",
    "\n",
    "\n",
    "## static has:\n",
    "\n",
    "0\"Land-sea mask\"\n",
    "\n",
    "1\"Angle of sub-gridscale orography (rad)\n",
    "\n",
    "2\"Anisotropy of sub-gridscale orography\"\n",
    "\n",
    "3\"Standard deviation of sub-gridscale orography\"\n",
    "\n",
    "4\"Slope of sub-gridscale orography\"\n",
    "\n",
    "## Y has:\n",
    "\n",
    "0\"ERA5 Precipitation (mm/hr)\"\n",
    "\n",
    "1\"TRMM Precipitation (mm/hr)\"\n",
    "\n",
    "2\"TRMM Relative Error (%)\"\n",
    "\n",
    "# plev are\n",
    "1000.,   2000.,   3000.,   5000.,   7000.,  10000., 15000.,\n",
    "20000.,  25000.,  30000.,  40000.,  50000.,  60000.,  70000.,80000.,  85000.,  90000.,  92500.,  95000.,  97500., 100000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X2d_raw = jnp.array(jnp.load(\"../data/ERA/NPY_DATA/X2d_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "X3d_raw = jnp.array(jnp.load(\"../data/ERA/NPY_DATA/X3d_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "Xstatic_raw = jnp.array(jnp.load(\"../data/ERA/NPY_DATA/XStatic_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "Y_raw = jnp.array(jnp.load(\"../data/ERA/NPY_DATA/Y_sample.npy\"), dtype=jnp.float64) # [N, 1]\n",
    "# X2d_raw = jnp.array(jnp.load(\"../data/100_000_one_day/X2D_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "# X3d_raw = jnp.array(jnp.load(\"../data/100_000_one_day/X3D_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "# Xstatic_raw = jnp.array(jnp.load(\"../data/100_000_one_day/XSTATIC_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "# Y_raw = jnp.array(jnp.load(\"../data/100_000_one_day/Y_sample.npy\"), dtype=jnp.float64) # [N, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pressure = jnp.array([[1000,2000,3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,60000,70000,80000, 85000,90000,92500,95000,97500,100000]], dtype=jnp.float64)\n",
    "\n",
    "# random shuffle\n",
    "X2d = jr.permutation(key, X2d_raw)\n",
    "X3d = jr.permutation(key, X3d_raw)\n",
    "Xstatic = jr.permutation(key, Xstatic_raw)\n",
    "Y = jr.permutation(key, Y_raw)\n",
    "\n",
    "# look at ERA5 rain\n",
    "Y = Y[:,0:1]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# just keep the \"prognostic\" 3d inputs that joe considered (for now)\n",
    "# RH, tehta_e^+, theta_e, theta_e^*\n",
    "names_3d =  [\"Absolute temperature,\",\"Relative Humidity\", \"Specific Humidity\", \"Geopotential Height\", \"Zonal Wind\",\"Meridional Wind\",\"Potential Temperature (theta)\",\"Equivalent Potential Temperature (tehta_e)\", \"Equivalent Potential Temperature Saturation Deficit (theta_e+)\", \"Saturated Equivalent Potential Temperature (theta_e*)\", \"MSE-conserving Plume Buoyancy\"]\n",
    "names_3d_short =  [\"K,\",\"RH\", \"q\", \"gh\", \"wind_z\",\"wind_m\",\"theta\",\"tehta_e\", \"theta_e+\", \"theta_e*\", \"plume\"]\n",
    "idx_3d = [1,4,5,6,7,8,9]\n",
    "# idx_3d = [1, 7, 8, 9]\n",
    "names_3d = [names_3d[i] for i in idx_3d]\n",
    "names_3d_short = [names_3d_short[i] for i in idx_3d]\n",
    "X3d = X3d[:,idx_3d,:]\n",
    "\n",
    "\n",
    "# # also use his \"normalisatopm\" for sigma_o\n",
    "sigma_o = jnp.where(Xstatic[:,0]<0.5, 0.0, 1.0+jnp.log(1+Xstatic[:,3])) # optimize threshold?\n",
    "Xstatic = Xstatic.at[:,3].set(sigma_o)\n",
    "Xstatic = Xstatic.at[:,0].set(jnp.log(Xstatic[:,0] / (1- Xstatic[:,0])))\n",
    "names_static = [\"Land-sea Mask\",\"Angle of sub-gridscale orography\",\"Anisotropy of sub-gridscale orography\",\"Stdev of sub-gridscale orography\",\"Slope of sub-gridscale orography\"]\n",
    "names_static_short = [\"LSM\",\"O_angle\",\"O_anisotrophy\",\"O_sd\",\"O_slope\"]\n",
    "idx_static = [0, 3]\n",
    "names_static = [names_static[i] for i in idx_static]\n",
    "names_static_short = [names_static_short[i] for i in idx_static]\n",
    "Xstatic = Xstatic[:,idx_static]\n",
    "\n",
    "names_2d = [\"Sea Surface temperature\", \"Sensible heat flux\", \"Latent heat flux\", \"Vertically-integrated moisture convergence\", \"Column relative humidity\"]\n",
    "names_2d_short = [\"T_surface\",\"flux_s\",\"flux_l\",\"moisture\",\"CRH\"]\n",
    "idx_2d = [1,2]\n",
    "names_2d = [names_2d[i] for i in idx_2d]\n",
    "names_2d_short = [names_2d_short[i] for i in idx_2d]\n",
    "X2d = X2d[:,idx_2d]\n",
    "\n",
    "\n",
    "\n",
    "#remove all pressure levels above 500 hPA\n",
    "lowest_idx =  11 #7\n",
    "print(f\"Removed all pressure levels below {pressure[:,lowest_idx]} hPa\")\n",
    "X3d = X3d[:, :, lowest_idx:]\n",
    "pressure_levels = pressure[:,lowest_idx:]\n",
    "pressure_mean = jnp.mean(pressure_levels)\n",
    "pressure_std = jnp.std(pressure_levels)\n",
    "pressure_levels = (pressure_levels - pressure_mean) / pressure_std\n",
    "\n",
    "\n",
    "\n",
    "# remove any entries with nan\n",
    "X3d_nan_idx = jnp.isnan(X3d).any(axis=1).any(axis=1)\n",
    "X2d_nan_idx = jnp.isnan(X2d).any(axis=1)\n",
    "Xstatic_nan_idx = jnp.isnan(Xstatic).any(axis=1)\n",
    "Y_nan_idx = jnp.isnan(Y).any(axis=1)\n",
    "any_nan = X3d_nan_idx | X2d_nan_idx | Y_nan_idx | Xstatic_nan_idx\n",
    "no_nan = ~ any_nan\n",
    "print(f\"Removed {any_nan.sum()} entries with nan\")\n",
    "X2d = X2d[no_nan,:]\n",
    "X3d = X3d[no_nan,:,:]\n",
    "Xstatic = Xstatic[no_nan,:]\n",
    "Y = Y[no_nan,:]\n",
    "\n",
    "\n",
    "# # remove no rain days\n",
    "# print(f\"Removed {(Y[:,0]==0).sum()} entries with zero rain\")\n",
    "# X3d = X3d[Y[:,0]>0,:]\n",
    "# X2d = X2d[Y[:,0]>0,:]\n",
    "# Xstatic = Xstatic[Y[:,0]>0,:]\n",
    "# Y = Y[Y[:,0]>0,:]\n",
    "\n",
    "\n",
    "\n",
    "#also log Y\n",
    "# print(f\"Applied log transform to Y\")\n",
    "# Y = jnp.log(Y-jnp.min(Y)+1e-3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_2d_variables= X2d.shape[1]\n",
    "num_3d_variables= X3d.shape[1]\n",
    "num_static_variables= Xstatic.shape[1]\n",
    "num_not_3d_variables = num_2d_variables + num_static_variables\n",
    "num_variables = num_2d_variables + num_3d_variables + num_static_variables\n",
    "print(f\"using {num_static_variables} static variables\")\n",
    "print(f\"using {num_2d_variables} 2d variables\")\n",
    "print(f\"using {num_3d_variables} 3d variables\")\n",
    "names = names_3d + names_2d + names_static\n",
    "names_short = names_3d_short + names_2d_short + names_static_short\n",
    "print(f\"using variables with names {names_short}\")\n",
    "\n",
    "\n",
    "problem_info = ProblemInfo(\n",
    "    num_2d_variables = num_2d_variables,\n",
    "    num_3d_variables = num_3d_variables,\n",
    "    num_static_variables = num_static_variables,\n",
    "    names_2d_short = names_2d_short,\n",
    "    names_3d_short = names_3d_short,\n",
    "    names_static_short = names_static_short,\n",
    "    names_2d = names_2d,\n",
    "    names_3d = names_3d,\n",
    "    names =names,\n",
    "    names_static = names_static,\n",
    "    num_variables = num_variables,\n",
    "    pressure_levels = pressure_levels,\n",
    "    pressure_mean = pressure_mean,\n",
    "    pressure_std = pressure_std,\n",
    ")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D = VerticalDataset(\n",
    "    X2d = X2d,\n",
    "    X3d = X3d,\n",
    "    Xstatic = Xstatic,\n",
    "    y=Y,\n",
    "    standardize=True,\n",
    "    standardize_with_NF=False,\n",
    ")\n",
    "\n",
    "plot_data(problem_info,D)\n",
    "\n",
    "# plot_marginals(problem_info, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_log_prior(tau=None) -> callable:\n",
    "\n",
    "    def log_prior(model):\n",
    "        log_prob = 0.0\n",
    "\n",
    "        # if hasattr(model, \"smoother\"):\n",
    "        #     smoother_input_scale_prior = tfd.LogNormal(0.0,1.0)\n",
    "        #     smoother_mean_prior = tfd.Uniform(jnp.min(model.smoother.Z_levels),jnp.max(model.smoother.Z_levels))\n",
    "        #     log_prob += jnp.sum(smoother_mean_prior.log_prob(model.smoother.smoother_mean))\n",
    "        #     log_prob += jnp.sum(smoother_input_scale_prior.log_prob(model.smoother.smoother_input_scale))\n",
    "\n",
    "        lengthscales = jnp.vstack([k.lengthscale for k in model.base_kernels])\n",
    "        variances = model.interaction_variances\n",
    "       \n",
    "        #variance_prior = tfd.Gamma(1.0,0.2)\n",
    "        #log_prob += jnp.sum(variance_prior.log_prob(variances))\n",
    "\n",
    "        d = lengthscales.size\n",
    "        # #l_prior = tfd.LogNormal(jnp.sqrt(2.0) + jnp.log(d)/2.0,jnp.sqrt(1.0))\n",
    "        # #l_prior = tfd.Gamma(3.0*d,6.0)\n",
    "        #l_prior = tfd.Gamma(3.0,6.0)\n",
    "        #log_prob += jnp.sum(l_prior.log_prob(lengthscales))\n",
    "        l_prior = tfd.HalfCauchy(0.0,tau)\n",
    "        log_prob += jnp.sum(l_prior.log_prob((1.0 / lengthscales**2)))\n",
    "            \n",
    "        #noise_prior = tfd.LogNormal(0.0,10)\n",
    "        #log_prob += noise_prior.log_prob(model.likelihood.obs_stddev)\n",
    "\n",
    "        return log_prob\n",
    "    \n",
    "    return log_prior\n",
    "\n",
    "\n",
    "\n",
    "def init_smoother():\n",
    "    smoother_input_scale_bijector = tfb.Softplus(low=jnp.array(1e-1, dtype=jnp.float64))\n",
    "    smoother_mean_bijector =  tfb.SoftClip(low=jnp.min(pressure_levels+1e-3), high=jnp.max(pressure_levels-1e-3))\n",
    "    smoother = VerticalSmoother(\n",
    "        jnp.array([[0.0]*num_3d_variables]), \n",
    "        jnp.array([[1.0]*num_3d_variables]), \n",
    "        Z_levels=pressure_levels\n",
    "        ).replace_bijector(smoother_input_scale=smoother_input_scale_bijector,smoother_mean=smoother_mean_bijector)\n",
    "    return smoother\n",
    "\n",
    "\n",
    "def init_kernels(data):\n",
    "    lengthscale_bij = tfb.SoftClip(low=jnp.array(1e-1, dtype=jnp.float64), high=jnp.array(1e1, dtype=jnp.float64))\n",
    "    return  [gpx.kernels.RBF(lengthscale=jnp.array([1.0]), active_dims=[i]).replace_trainable(variance=False).replace_bijector(lengthscale = lengthscale_bij) for i in range(data.dim)]\n",
    "\n",
    "def init_likelihood(data, obs_stddev = jnp.array(1.0, dtype=jnp.float64) ):\n",
    "    obs_bij=tfb.Softplus(low=jnp.array(1e-3, dtype=jnp.float64))\n",
    "    return gpx.likelihoods.Gaussian(num_datapoints=data.n, obs_stddev=obs_stddev).replace_bijector(obs_stddev=obs_bij)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep fancy kernel for model\n",
    "# first fit with small data to get init for SVGP\n",
    "num_data_for_init=100\n",
    "D_small = D.get_subset(num_data_for_init, space_filling=False,use_output=True)\n",
    "\n",
    "plot_data(problem_info, D_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with small data\n",
    "starting_var = jnp.var(D_small.y)\n",
    "posterior = ConjugatePrecipGP(\n",
    "    base_kernels=init_kernels(D_small), \n",
    "    likelihood=init_likelihood(D_small, obs_stddev = jnp.array(1.0, dtype=jnp.float64) ),\n",
    "    smoother=init_smoother(),\n",
    "    max_interaction_depth=2,\n",
    "    interaction_variances=jnp.array([starting_var/3.0]*3, dtype=jnp.float64),\n",
    "    jitter=jnp.array(1e-5, dtype=jnp.float64),\n",
    "    measure=None,\n",
    "    second_order_empirical=False,\n",
    "    )\n",
    "plt.figure()\n",
    "opt_posterior, history = gpx.fit_scipy(\n",
    "        model=posterior,\n",
    "        objective=jax.jit(posterior.loss_fn(negative=True, log_prior=None, use_loocv=True)),#build_log_prior(tau=1.0))),\n",
    "        train_data=D_small,\n",
    "        safe=False,\n",
    "    )\n",
    "\n",
    "# opt_posterior, history = gpx.fit(\n",
    "\n",
    "#         model=posterior,\n",
    "#         objective=jax.jit(posterior.loss_fn(negative=True, log_prior=build_log_prior(tau=0.1))),\n",
    "#         train_data=D_small,\n",
    "#         optim=ox.adam(1e-1),\n",
    "#         num_iters=200,\n",
    "#         safe=False,\n",
    "#         key=key,\n",
    "#     )\n",
    "\n",
    "\n",
    "plt.plot(history)\n",
    "plot_params(problem_info, opt_posterior,D_small, title=\"initial fit with small data\", print_corr=True)\n",
    "print(f\"noise is {opt_posterior.likelihood.obs_stddev}\")\n",
    "print(f\"interaction vars {opt_posterior.interaction_variances}\")\n",
    "plot_interactions(problem_info, opt_posterior, D_small, k=10, use_range=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "starting_var = jnp.var(D.y)\n",
    "num_inducing=10\n",
    "inducing_inputs = opt_posterior.smoother.smooth_data(D_small)[0][:num_inducing]\n",
    "#variational_mean = jnp.zeros((num_inducing, 1))\n",
    "variational_mean = opt_posterior.predict(inducing_inputs, D_small).mean()[:,None]\n",
    "variational_root_covariance = jnp.eye(num_inducing)\n",
    "\n",
    "\n",
    "variational_posterior = VariationalPrecipGP(\n",
    "    base_kernels=opt_posterior.base_kernels, \n",
    "    likelihood=opt_posterior.likelihood,\n",
    "    smoother=opt_posterior.smoother,\n",
    "    max_interaction_depth=opt_posterior.max_interaction_depth,\n",
    "    interaction_variances=opt_posterior.interaction_variances,\n",
    "    jitter=jnp.array(1e-5, dtype=jnp.float64),\n",
    "    measure=opt_posterior.measure,\n",
    "    second_order_empirical=opt_posterior.second_order_empirical,\n",
    "    inducing_inputs=inducing_inputs,\n",
    "    variational_mean=variational_mean,\n",
    "    variational_root_covariance=variational_root_covariance,\n",
    "    )\n",
    "plt.figure()\n",
    "\n",
    "variational_posterior = variational_posterior.replace_trainable(inducing_inputs=False)\n",
    "\n",
    "opt_variational_posterior, history = gpx.fit(\n",
    "        model=variational_posterior,\n",
    "        objective=variational_posterior.loss_fn(negative=True, log_prior=None), #todo rejit\n",
    "        train_data=D,\n",
    "        optim=ox.adam(1e-1),\n",
    "        num_iters=200,\n",
    "        batch_size=500,\n",
    "        safe=False,\n",
    "        key=key,\n",
    "    )\n",
    "\n",
    "plt.plot(history)\n",
    "plot_params(problem_info, opt_variational_posterior,D_small, title=\"initial fit with small data\", print_corr=True)\n",
    "print(f\"noise is {opt_variational_posterior.likelihood.obs_stddev}\")\n",
    "print(f\"interaction vars {opt_variational_posterior.interaction_variances}\")\n",
    "plot_interactions(problem_info, opt_variational_posterior, D_small, k=10, use_range=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
