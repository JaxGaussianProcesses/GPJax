# Copyright 2024 The GPJax Contributors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Abstract base classes and interfaces for pathwise sampling.

This module defines the core abstractions for pathwise sampling of Gaussian
processes, following the methodology of Wilson et al. (2020). The abstractions
enable modular construction of samplers with different feature generation
strategies and weight sampling approaches.

References:
    Wilson, J., Borovitskiy, V., Terenin, A., Mostowsky, P., & Deisenroth, M. (2020).
    Efficiently sampling functions from Gaussian process posteriors.
    International Conference on Machine Learning.
"""

from __future__ import annotations

from abc import (
    ABC,
    abstractmethod,
)

import beartype.typing as tp
from beartype import beartype
from flax import nnx
from jaxtyping import (
    Array,
    Float,
    jaxtyped,
)

from gpjax.dataset import Dataset
from gpjax.gps import AbstractPrior
from gpjax.typing import (
    FunctionalSample,
    KeyArray,
)


class AbstractFeatureGenerator(ABC):
    """Abstract base class for feature generators in pathwise sampling.
    
    Feature generators produce the basis functions φᵢ(x) used in the finite
    feature approximation of Gaussian processes. Different generators implement
    different strategies for constructing these features.
    
    The finite feature approximation takes the form:
        f̂(x) = Σᵢ φᵢ(x)θᵢ
    
    where φᵢ are the features and θᵢ are the weights.
    """

    @abstractmethod
    @jaxtyped(typechecker=beartype)
    def generate_features(
        self,
        test_inputs: Float[Array, "N D"],
        key: KeyArray,
    ) -> Float[Array, "N F"]:
        """Generate feature evaluations at test inputs.
        
        Args:
            test_inputs: Input locations where features should be evaluated.
                Shape: (N, D) where N is number of inputs, D is dimensionality.
            key: Random key for feature generation (if needed).
            
        Returns:
            Feature evaluations with shape (N, F) where F is the number of features.
        """
        ...

    @property
    @abstractmethod
    def num_features(self) -> int:
        """Number of features generated by this generator."""
        ...


class AbstractWeightSampler(ABC):
    """Abstract base class for weight sampling in pathwise sampling.
    
    Weight samplers generate the coefficients θᵢ that multiply the basis
    functions in the finite feature approximation. Different samplers
    implement different strategies for drawing these weights.
    """

    @abstractmethod
    @jaxtyped(typechecker=beartype)
    def sample_weights(
        self,
        num_samples: int,
        num_features: int,
        key: KeyArray,
    ) -> Float[Array, "B F"]:
        """Sample weights for feature combinations.
        
        Args:
            num_samples: Number of function samples to generate.
            num_features: Number of features that need weights.
            key: Random key for weight sampling.
            
        Returns:
            Weights with shape (B, F) where B is batch size (num_samples)
            and F is number of features.
        """
        ...


class AbstractPathwiseSampler(nnx.Module, ABC):
    """Abstract base class for pathwise sampling of Gaussian processes.
    
    Pathwise samplers provide approximate functional samples from Gaussian
    process priors and posteriors using finite feature approximations.
    This enables consistent function evaluations across arbitrary inputs
    without cubic scaling costs.
    
    The approach follows Wilson et al. (2020) and provides the foundation
    for both prior and posterior sampling with different feature strategies.
    """

    def __init__(
        self,
        prior: AbstractPrior,
        feature_generator: tp.Optional[AbstractFeatureGenerator],
        weight_sampler: tp.Optional[AbstractWeightSampler],
        jitter: float = 1e-6,
    ):
        """Initialize the pathwise sampler.
        
        Args:
            prior: The Gaussian process prior.
            feature_generator: Generator for basis functions.
            weight_sampler: Sampler for feature weights.
            jitter: Small value for numerical stability.
        """
        self.prior = prior
        self.feature_generator = feature_generator
        self.weight_sampler = weight_sampler
        self.jitter = jitter

    @abstractmethod
    @jaxtyped(typechecker=beartype)
    def sample(
        self,
        num_samples: int,
        key: KeyArray,
        **kwargs,
    ) -> FunctionalSample:
        """Generate approximate functional samples.
        
        Args:
            num_samples: Number of function samples to generate.
            key: Random key for sampling.
            **kwargs: Additional arguments specific to sampler type.
            
        Returns:
            A function that evaluates samples at arbitrary test inputs.
            The function signature is: (test_inputs) -> sample_values
            where test_inputs has shape (N, D) and sample_values has shape (N, B).
        """
        ...

    @property
    def num_features(self) -> int:
        """Total number of features used by this sampler."""
        if self.feature_generator is None:
            return 0
        return self.feature_generator.num_features


# Type aliases for protocols
FeatureGeneratorProtocol = tp.Protocol
WeightSamplerProtocol = tp.Protocol


class PathwiseSamplerConfig(tp.TypedDict, total=False):
    """Configuration dictionary for pathwise samplers.
    
    This TypedDict defines the standard configuration options available
    for pathwise samplers, enabling flexible configuration while maintaining
    type safety.
    """
    
    num_fourier_features: int
    num_canonical_features: int
    jitter: float
    weight_strategy: str
    feature_strategy: str


__all__ = [
    "AbstractFeatureGenerator",
    "AbstractWeightSampler", 
    "AbstractPathwiseSampler",
    "PathwiseSamplerConfig",
]