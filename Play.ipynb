{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "import jax\n",
    "from dataclasses import dataclass\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "\n",
    "#with install_import_hook(\"gpjax\", \"beartype.beartype\"):\n",
    "import gpjax as gpx\n",
    "from gpjax.distributions import GaussianDistribution\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "# plt.style.use(\n",
    "#     \"https://raw.githubusercontent.com/JaxGaussianProcesses/GPJax/main/docs/examples/gpjax.mplstyle\"\n",
    "# )\n",
    "# colors = rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "key = jr.PRNGKey(123)\n",
    "\n",
    "import optax as ox\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "\n",
    "# custom bits\n",
    "from gpjax.dataset import VerticalDataset\n",
    "from gpjax.kernels.stationary.rbf import OrthogonalRBF\n",
    "from gpjax.gps import CustomAdditiveConjugatePosterior, VerticalSmoother\n",
    "from gpjax.objectives import CustomConjugateMLL, CustomELBO, custom_variational_expectation\n",
    "from gpjax.optim_utils import optim_builder, zero_grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100_000 entries sampled across time/lat/lon over first day of data\n",
    "\n",
    "## X2D has:\n",
    "\n",
    "0\"Sea surface temperature (K)\"\n",
    "\n",
    "1\"Sensible heat flux (W/m^2)\"\n",
    "\n",
    "2\"Latent heat flux (W/m^2)\"\n",
    "\n",
    "3\"Vertically-integrated moisture convergence (kg/m^2)\"\n",
    "\n",
    "4\"Column relative humidity (%)\"\n",
    "\n",
    "\n",
    "## X3D has:\n",
    "\n",
    "0\"Absolute temperature (K)\"\n",
    "\n",
    "1\"Relative humidity (%)\"\n",
    "\n",
    "2\"Specific humidity (kg/kg)\"\n",
    "\n",
    "3\"Geopotential height (m^2 s^-2)\"\n",
    "\n",
    "4\"Zonal wind (m/s)\"\n",
    "\n",
    "5\"Meridional wind (m/s)\"\n",
    "\n",
    "6\"Potential temperature (K)\"\n",
    "\n",
    "7\"Equivalent potential temperature (K)\"\n",
    "\n",
    "8\"Equivalent potential temperature saturation deficit (K)\"\n",
    "\n",
    "9\"Saturated equivalent potential temperature (K)\"\n",
    "\n",
    "10\"MSE-conserving plume buoyancy (m/s^2)\"\n",
    "\n",
    "\n",
    "## static has:\n",
    "\n",
    "0\"Land-sea mask\"\n",
    "\n",
    "1\"Angle of sub-gridscale orography (rad)Anisotropy of sub-gridscale orography\"\n",
    "\n",
    "2\"Standard deviation of sub-gridscale orography\"\n",
    "\n",
    "3\"Slope of sub-gridscale orography\"\n",
    "\n",
    "## Y has:\n",
    "\n",
    "0\"ERA5 Precipitation (mm/hr)\"\n",
    "\n",
    "1\"TRMM Precipitation (mm/hr)\"\n",
    "\n",
    "2\"TRMM Relative Error (%)\"\n",
    "\n",
    "# plev are\n",
    "1000.,   2000.,   3000.,   5000.,   7000.,  10000., 15000.,\n",
    "20000.,  25000.,  30000.,  40000.,  50000.,  60000.,  70000.,80000.,  85000.,  90000.,  92500.,  95000.,  97500., 100000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X2d = jnp.array(jnp.load(\"..//data/100_000_one_day/X2D_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "X3d = jnp.array(jnp.load(\"../data/100_000_one_day/X3D_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "Xstatic = jnp.array(jnp.load(\"../data/100_000_one_day/XSTATIC_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "Y = jnp.array(jnp.load(\"../data/100_000_one_day/Y_sample.npy\"), dtype=jnp.float64) # [N, 1]\n",
    "pressure = jnp.array([[1000,2000,3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,60000,70000,80000, 85000,90000,92500,95000,97500,100000]], dtype=jnp.float64)\n",
    "\n",
    "\n",
    "# random shuffle\n",
    "X2d = jr.permutation(key, X2d)\n",
    "X3d = jr.permutation(key, X3d)\n",
    "Xstatic = jr.permutation(key, Xstatic)\n",
    "Y = jr.permutation(key, Y)\n",
    "\n",
    "# look at ERA5 rain\n",
    "Y = Y[:,0:1]  \n",
    "\n",
    "# remove any entries with nan\n",
    "X3d_nan_idx = jnp.isnan(X3d).any(axis=1).any(axis=1)\n",
    "X2d_nan_idx = jnp.isnan(X2d).any(axis=1)\n",
    "Xstatic_nan_idx = jnp.isnan(Xstatic).any(axis=1)\n",
    "Y_nan_idx = jnp.isnan(Y).any(axis=1)\n",
    "any_nan = X3d_nan_idx | X2d_nan_idx | Y_nan_idx | Xstatic_nan_idx\n",
    "no_nan = ~ any_nan\n",
    "print(f\"Removed {any_nan.sum()} entries with nan\")\n",
    "X2d = X2d[no_nan,:]\n",
    "X3d = X3d[no_nan,:,:]\n",
    "Xstatic = Xstatic[no_nan,:]\n",
    "Y = Y[no_nan,:]\n",
    "\n",
    "\n",
    "# just keep the \"prognostic\" 3d inputs that joe considered (for now)\n",
    "# RH, tehta_e^+, theta_e, theta_e^*\n",
    "names_3d =  [\"K,\",\"RH\", \"q\", \"gh\", \"wind_z\",\"wind_m\",\"theta\",\"tehta_e\", \"theta_e+\", \"theta_e*\", \"plume\"]\n",
    "#idx_3d = [i for i in range(len(names_3d))]\n",
    "idx_3d = [1, 7, 8, 9]\n",
    "names_3d = [names_3d[i] for i in idx_3d]\n",
    "X3d = X3d[:,idx_3d,:]\n",
    "\n",
    "\n",
    "# # also use his \"normalisatopm\" for sigma_o\n",
    "#sigma_o = jnp.where(Xstatic[:,0]<0.5, 0.0, 1.0+jnp.log(1+Xstatic[:,2])) # optimize threshold?\n",
    "#Xstatic = Xstatic.at[:,2].set(sigma_o)\n",
    "names_static = [\"LSM\",\"O_angle\",\"O_sd\",\"O_slope\"]\n",
    "idx_static = [i for i in range(len(names_static))]\n",
    "# idx_static = [0]\n",
    "# idx_static = []\n",
    "names_static = [names_static[i] for i in idx_static]\n",
    "Xstatic = Xstatic[:,idx_static]\n",
    "\n",
    "\n",
    "names_2d = [\"K_surface\",\"flux_s\",\"flux_l\",\"moisture\",\"CRH\"]\n",
    "idx_2d =[i for i in range(len(names_2d))]\n",
    "# idx_2d = []\n",
    "names_2d = [names_2d[i] for i in idx_2d]\n",
    "X2d = X2d[:,idx_2d]\n",
    "\n",
    "\n",
    "#remove all pressure levels below 500 hPA\n",
    "lowest_idx =  7  # 11\n",
    "print(f\"Removed all pressure levels below {pressure[:,lowest_idx]} hPa\")\n",
    "X3d = X3d[:, :, lowest_idx:]\n",
    "pressure_levels = pressure[:,lowest_idx:]\n",
    "\n",
    "# # remove no rain days\n",
    "# print(f\"Removed {(Y[:,0]==0).sum()} entries with zero rain\")\n",
    "# X3d = X3d[Y[:,0]>0,:]\n",
    "# X2d = X2d[Y[:,0]>0,:]\n",
    "# Xstatic = Xstatic[Y[:,0]>0,:]\n",
    "# Y = Y[Y[:,0]>0,:]\n",
    "\n",
    "\n",
    "# also log Y\n",
    "print(f\"Applied log transform to Y\")\n",
    "Y = jnp.log(Y-jnp.min(Y)+1e-12)\n",
    "print(f\"then standardized Y\")\n",
    "Y_mean = jnp.mean(Y)\n",
    "Y_std = jnp.std(Y)\n",
    "Y = (Y - Y_mean) / Y_std\n",
    "\n",
    "# # standardize inputs (THIS NOW HAPPENS IN MODEL)\n",
    "\n",
    "# X3d_std = jnp.std(X3d, axis=(0))\n",
    "# X3d_mean = jnp.mean(X3d,axis=(0))\n",
    "# X3d = (X3d - X3d_mean[None,:,:]) / X3d_std[None,:,:]\n",
    "# X2d_std = jnp.std(X2d, axis=0)\n",
    "# X2d_mean = jnp.mean(X2d,axis=0)\n",
    "# X2d = (X2d - X2d_mean) / X2d_std\n",
    "# Xstatic_std = jnp.std(Xstatic, axis=0)\n",
    "# Xstatic_mean = jnp.mean(Xstatic,axis=0)\n",
    "# Xstatic = (Xstatic - Xstatic_mean) / Xstatic_std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# look at all data but 1_000 test\n",
    "\n",
    "N_test = 100\n",
    "N_train = len(X2d) - N_test \n",
    "print(f\"Using {N_train} training and {N_test} testing points!\")\n",
    "num_2d_variables= X2d.shape[1]\n",
    "num_3d_variables= X3d.shape[1]\n",
    "num_static_variables= Xstatic.shape[1]\n",
    "num_not_3d_variables = num_2d_variables + num_static_variables\n",
    "num_variables = num_2d_variables + num_3d_variables + num_static_variables\n",
    "print(f\"using {num_static_variables} static variables\")\n",
    "print(f\"using {num_2d_variables} 2d variables\")\n",
    "print(f\"using {num_3d_variables} 3d variables\")\n",
    "names = names_3d + names_2d + names_static\n",
    "print(f\"using variables with names {names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_params(model, title=\"\"):\n",
    "    if isinstance(model, gpx.variational_families.AbstractVariationalFamily):\n",
    "        model = model.posterior\n",
    "    plt.figure()\n",
    "    if isinstance(model.prior.kernel, gpx.kernels.AdditiveKernel):\n",
    "        lengthscales = jnp.array([model.prior.kernel.kernels[i].lengthscale[0] for i in range(num_variables)])\n",
    "    else:\n",
    "        lengthscales = model.prior.kernel.lengthscale\n",
    "    smoothing_weights = model.smoother.smooth() # [4, 21]\n",
    "    for i in range(num_3d_variables):\n",
    "        plt.plot(smoothing_weights[i,:].T,pressure_levels[0,:], label=f\"{names_3d[i]} with lengthscales_ {lengthscales[i]:.2f}\")\n",
    "    plt.legend()\n",
    "    plt.title(title+f\" other lengthscales are {lengthscales[num_3d_variables:]}\")\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OrthogonalRBF(OrthogonalRBF):\n",
    "    dummy: gpx.kernels.AbstractKernel = gpx.kernels.RBF()\n",
    "\n",
    "\n",
    "\n",
    "# prep fancy kernel for model\n",
    "# first fit with small data to get init for SVGP\n",
    "num_data_for_init=200\n",
    "D_small = VerticalDataset(\n",
    "    X2d = X2d[:num_data_for_init,:],\n",
    "    X3d = X3d[:num_data_for_init,:,:],\n",
    "    Xstatic = Xstatic[:num_data_for_init,:],\n",
    "    y=Y[:num_data_for_init,:],\n",
    ")\n",
    "\n",
    "lengthscale_bij = tfb.SoftClip(jnp.array(1e-1, dtype=jnp.float64),jnp.array(1e2, dtype=jnp.float64))\n",
    "variance_bij = tfb.SoftClip(jnp.array(1e-5, dtype=jnp.float64),jnp.array(1e2, dtype=jnp.float64))\n",
    "noise_bij = tfb.SoftClip(jnp.array(1e-2, dtype=jnp.float64),jnp.array(1e1, dtype=jnp.float64))\n",
    "\n",
    "smoother = VerticalSmoother(\n",
    "    jnp.array([[0.0]*num_3d_variables]), \n",
    "    jnp.array([[1.0]*num_3d_variables]), \n",
    "    Z_levels=pressure_levels)\n",
    "smoother_input_scale_bij = tfb.SoftClip(jnp.array(1e-1, dtype=jnp.float64),jnp.array(5.0, dtype=jnp.float64))\n",
    "smoother_mean_bij = tfb.SoftClip(jnp.array(jnp.min(smoother.Z_levels), dtype=jnp.float64),jnp.array(jnp.max(smoother.Z_levels), dtype=jnp.float64))\n",
    "smoother = smoother.replace_bijector(smoother_mean=smoother_mean_bij,smoother_input_scale=smoother_input_scale_bij)\n",
    "\n",
    "\n",
    "#base_kernels = [gpx.kernels.RBF(lengthscale=jnp.array([2.0]), active_dims=[i]).replace_bijector(lengthscale=lengthscale_bij).replace_trainable(variance=False) for i in range(num_variables)]\n",
    "base_kernels= [OrthogonalRBF(lengthscale=jnp.array([2.]), active_dims=[i]).replace_bijector(lengthscale=lengthscale_bij) for i in range(num_variables)]\n",
    "max_interaction = 2\n",
    "kernel = gpx.kernels.AdditiveKernel(kernels=base_kernels,interaction_variances=jnp.array([1.0 / (max_interaction + 1)]*(max_interaction + 1)), max_interaction_depth=max_interaction).replace_bijector(interaction_variances=variance_bij)\n",
    "#kernel = kernel.replace_trainable(interaction_variances=False)\n",
    "\n",
    "prior = gpx.gps.Prior(mean_function= gpx.mean_functions.Zero(), kernel = kernel)\n",
    "likelihood = gpx.likelihoods.Gaussian(num_datapoints=num_data_for_init, obs_stddev=jnp.array(0.5, dtype=jnp.float64)).replace_bijector(obs_stddev=noise_bij)#.replace_trainable(obs_stddev=False)\n",
    "posterior = CustomAdditiveConjugatePosterior(prior=prior, likelihood=likelihood, smoother=smoother)\n",
    "\n",
    "plt.figure()\n",
    "objective = jax.jit(CustomConjugateMLL(negative=True))\n",
    "# opt_posterior, history = gpx.fit(\n",
    "#     model=posterior,\n",
    "#     objective=objective,\n",
    "#     train_data=D_small,\n",
    "#     optim=ox.adam(learning_rate=1e-2),\n",
    "#     num_iters=1_000,\n",
    "#     key=jr.PRNGKey(42),\n",
    "#     safe=False,\n",
    "# )\n",
    "opt_posterior, history = gpx.fit_scipy(\n",
    "    model=posterior,\n",
    "    objective=objective,\n",
    "    train_data=D_small,\n",
    "    safe=False,\n",
    ")\n",
    "plt.plot(history)\n",
    "plot_params(opt_posterior, title=\"initial fit with small data\")\n",
    "print(f\"noise is {opt_posterior.likelihood.obs_stddev}\")\n",
    "print(f\"interaction vars is {opt_posterior.prior.kernel.interaction_variances}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose inducing inputs and init SVGP\n",
    "# num_inducing = D_small.n\n",
    "# # z = jr.normal(key, (num_inducing , num_variables)) # allow this\n",
    "# z = opt_posterior.smoother.smooth_data(D_small)[0]\n",
    "\n",
    "\n",
    "# init_posterior_at_inducing = opt_posterior.predict(z, D_small)\n",
    "# D_full = VerticalDataset(\n",
    "#     X2d = X2d[:N_train,:],\n",
    "#     X3d = X3d[:N_train,:,:],\n",
    "#     Xstatic = Xstatic[:N_train,:],\n",
    "#     y=Y[:N_train,:],\n",
    "# )\n",
    "# # todo try whitening ?\n",
    "# q = gpx.variational_families.VariationalGaussian(\n",
    "#     posterior=opt_posterior, \n",
    "#     inducing_inputs=z,\n",
    "#     variational_mean= init_posterior_at_inducing.mean()[:,None],\n",
    "#     variational_root_covariance= jnp.eye(num_inducing, dtype=jnp.float64)#jnp.linalg.cholesky(init_posterior_at_inducing.covariance() + 1e-3 * jnp.eye(num_inducing)), # todo check this is right!\n",
    "# )\n",
    "\n",
    "# #q = q.replace_trainable(inducing_inputs=False)\n",
    "# # q = q.replace_trainable(variational_mean=False)\n",
    "# # q = q.replace_trainable(variational_root_covariance=False)\n",
    "\n",
    "# objective = jax.jit(CustomELBO(negative=True))\n",
    "\n",
    "# optim_pytree = q.replace(\n",
    "#     posterior = ox.adam(1e-2), \n",
    "#     variational_mean = ox.adam(1e-2),\n",
    "#     variational_root_covariance = ox.adam(1e-2), \n",
    "#     inducing_inputs= ox.adam(1e-1),\n",
    "#     )\n",
    "\n",
    "# optim = optim_builder(optim_pytree)\n",
    "\n",
    "# opt_q, history = gpx.fit(\n",
    "#     model=q,\n",
    "#     objective=objective,\n",
    "#     train_data=D_full,\n",
    "#     optim=optim,\n",
    "#     num_iters=200,\n",
    "#     key=jr.PRNGKey(42),\n",
    "#     batch_size=512,\n",
    "#     safe=False,\n",
    "# )\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(jnp.log(history))\n",
    "# plot_params(opt_q, title=\"full fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_1 = [[i] for i in range(num_variables)]\n",
    "idx_2 = []\n",
    "for i in range(num_variables):\n",
    "    for j in range(i+1,num_variables):\n",
    "        idx_2.append([i,j])\n",
    "idxs = idx_1 + idx_2       \n",
    "sobols = opt_posterior.get_sobol_indicies(D_small, idxs)\n",
    "sobols = sobols / jnp.sum(sobols)\n",
    "plt.plot(sobols)\n",
    "plt.title(\"sobol indicies (left of red are 1d interactions)\")\n",
    "plt.axvline(x=num_variables, color=\"red\")\n",
    "k=5\n",
    "top_idx = jax.lax.top_k(sobols, k)[1]\n",
    "for idx in top_idx:\n",
    "    chosen_idx = idxs[idx]\n",
    "    plt.figure()\n",
    "    num_plot = 1_000 if len(chosen_idx)==1 else 10_000\n",
    "    x_train = opt_posterior.smoother.smooth_data(D_small)[0]\n",
    "    x_plot = jr.uniform(key, (num_plot, num_variables), minval=jnp.min(x_train, axis=0), maxval=jnp.max(x_train, axis=0))\n",
    "    posterior_dist = opt_posterior.predict_additive_component(x_plot, D_small, chosen_idx)\n",
    "    mean = posterior_dist.mean()\n",
    "    std = jnp.sqrt(posterior_dist.variance())\n",
    "\n",
    "    if len(chosen_idx)==1:\n",
    "        plt.scatter(x_plot[:,chosen_idx[0]],mean, color=\"blue\") \n",
    "        plt.scatter(x_plot[:,chosen_idx[0]],mean+ 1.96*std, color=\"red\") \n",
    "        plt.scatter(x_plot[:,chosen_idx[0]],mean- 1.96*std, color=\"red\") \n",
    "        plt.scatter(x_train[:,chosen_idx[0]],jnp.zeros_like(x_train[:,chosen_idx[0]]), color=\"green\")\n",
    "        plt.xlim([jnp.min(x_train[:,chosen_idx[0]]),jnp.max(x_train[:,chosen_idx[0]])])\n",
    "    elif len(chosen_idx)==2:\n",
    "        plt.scatter(x_plot[:,chosen_idx[0]],x_plot[:,chosen_idx[1]],c=mean)\n",
    "        plt.scatter(x_train[:,chosen_idx[0]],x_train[:,chosen_idx[1]], color=\"green\")\n",
    "        plt.xlim([jnp.min(x_train[:,chosen_idx[0]]),jnp.max(x_train[:,chosen_idx[0]])])\n",
    "        plt.ylim([jnp.min(x_train[:,chosen_idx[1]]),jnp.max(x_train[:,chosen_idx[1]])])\n",
    "    plt.title(f\"variable {[names[i] for i in chosen_idx]} with sobol index {sobols[idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
