{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "import jax\n",
    "import json\n",
    "from jax.tree_util import Partial\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "from typing import List, Union\n",
    "\n",
    "import cola\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jaxtyping import (\n",
    "    Array,\n",
    "    Float,\n",
    "    install_import_hook,\n",
    "    Num,\n",
    ")\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "\n",
    "#with install_import_hook(\"gpjax\", \"beartype.beartype\"):\n",
    "import gpjax as gpx\n",
    "from gpjax.typing import (\n",
    "    Array,\n",
    "    ScalarInt,\n",
    "    ScalarFloat,\n",
    ")\n",
    "from gpjax.distributions import GaussianDistribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "plt.style.use(\n",
    "    \"https://raw.githubusercontent.com/JaxGaussianProcesses/GPJax/main/docs/examples/gpjax.mplstyle\"\n",
    ")\n",
    "colors = rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "\n",
    "\n",
    "import gpjax as gpx\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "key = jr.PRNGKey(123)\n",
    "\n",
    "import scipy.optimize as spo\n",
    "from dataclasses import dataclass\n",
    "from gpjax.base import param_field, static_field\n",
    "import math\n",
    "from gpjax.kernels.base import AbstractKernel\n",
    "from gpjax.kernels import RBF\n",
    "import optax as ox\n",
    "from gpjax.kernels.stationary.utils import squared_distance\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "from gpjax.typing import (\n",
    "    Array,\n",
    "    ScalarFloat,\n",
    ")\n",
    "from jaxtyping import (\n",
    "    Float,\n",
    "    Num,\n",
    ")\n",
    "from simple_pytree import Pytree\n",
    "from optax import GradientTransformation\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optim_builder(optim_pytree):\n",
    "\n",
    "    def _init_leaf(o, p):\n",
    "        if isinstance(o, GradientTransformation):\n",
    "            return o.init(p)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _update_leaf(o, u, s, p):\n",
    "        if isinstance(o, GradientTransformation):\n",
    "            return tuple(o.update(u, s, p))\n",
    "        else:\n",
    "            return jtu.tree_map(jnp.zeros_like, p)\n",
    "\n",
    "    def _get_updates(o, u, p):\n",
    "        if isinstance(o, GradientTransformation):\n",
    "            return u[0]\n",
    "        else:\n",
    "            return u\n",
    "    \n",
    "    def _get_state(o, u):\n",
    "        if isinstance(o, GradientTransformation):\n",
    "            return u[1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def init_fn(params):\n",
    "        return jtu.tree_map(_init_leaf, optim_pytree, params, is_leaf=lambda x: isinstance(x, GradientTransformation))\n",
    "\n",
    "    def update_fn(updates, state, params):\n",
    "        updates_state = jtu.tree_map(_update_leaf, optim_pytree, updates, state, params, is_leaf=lambda x: isinstance(x, GradientTransformation))\n",
    "        updates = jtu.tree_map(_get_updates, optim_pytree, updates_state, params, is_leaf=lambda x: isinstance(x, GradientTransformation))\n",
    "        state = jtu.tree_map(_get_state, optim_pytree, updates_state, is_leaf=lambda x: isinstance(x, GradientTransformation))\n",
    "\n",
    "        return updates, state\n",
    "\n",
    "    return GradientTransformation(init_fn, update_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100_000 entries sampled across time/lat/lon over first day of data\n",
    "\n",
    "## X2D has:\n",
    "\n",
    "0\"Sea surface temperature (K)\"\n",
    "\n",
    "1\"Sensible heat flux (W/m^2)\"\n",
    "\n",
    "2\"Latent heat flux (W/m^2)\"\n",
    "\n",
    "3\"Vertically-integrated moisture convergence (kg/m^2)\"\n",
    "\n",
    "4\"Column relative humidity (%)\"\n",
    "\n",
    "\n",
    "## X3D has:\n",
    "\n",
    "0\"Absolute temperature (K)\"\n",
    "\n",
    "1\"Relative humidity (%)\"\n",
    "\n",
    "2\"Specific humidity (kg/kg)\"\n",
    "\n",
    "3\"Geopotential height (m^2 s^-2)\"\n",
    "\n",
    "4\"Zonal wind (m/s)\"\n",
    "\n",
    "5\"Meridional wind (m/s)\"\n",
    "\n",
    "6\"Potential temperature (K)\"\n",
    "\n",
    "7\"Equivalent potential temperature (K)\"\n",
    "\n",
    "8\"Equivalent potential temperature saturation deficit (K)\"\n",
    "\n",
    "9\"Saturated equivalent potential temperature (K)\"\n",
    "\n",
    "10\"MSE-conserving plume buoyancy (m/s^2)\"\n",
    "\n",
    "\n",
    "## static has:\n",
    "\n",
    "0\"Land-sea mask\"\n",
    "\n",
    "1\"Angle of sub-gridscale orography (rad)Anisotropy of sub-gridscale orography\"\n",
    "\n",
    "2\"Standard deviation of sub-gridscale orography\"\n",
    "\n",
    "3\"Slope of sub-gridscale orography\"\n",
    "\n",
    "## Y has:\n",
    "\n",
    "0\"ERA5 Precipitation (mm/hr)\"\n",
    "\n",
    "1\"TRMM Precipitation (mm/hr)\"\n",
    "\n",
    "2\"TRMM Relative Error (%)\"\n",
    "\n",
    "# plev are\n",
    "1000.,   2000.,   3000.,   5000.,   7000.,  10000., 15000.,\n",
    "20000.,  25000.,  30000.,  40000.,  50000.,  60000.,  70000.,80000.,  85000.,  90000.,  92500.,  95000.,  97500., 100000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 24779 entries with nan\n",
      "Removed all pressure levels below [20000.] hPa\n",
      "Applied log transform to Y\n",
      "then standardized Y\n",
      "Using 75121 training and 100 testing points!\n",
      "using 1 static variables\n",
      "using 0 2d variables\n",
      "using 4 3d variables\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X2d = jnp.array(jnp.load(\"..//data/100_000_one_day/X2D_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "X3d = jnp.array(jnp.load(\"../data/100_000_one_day/X3D_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "Xstatic = jnp.array(jnp.load(\"../data/100_000_one_day/XSTATIC_sample.npy\"), dtype=jnp.float64) # [N, D]\n",
    "Y = jnp.array(jnp.load(\"../data/100_000_one_day/Y_sample.npy\"), dtype=jnp.float64) # [N, 1]\n",
    "pressure = jnp.array([[1000,2000,3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,60000,70000,80000, 85000,90000,92500,95000,97500,100000]], dtype=jnp.float64)\n",
    "\n",
    "\n",
    "# random shuffle\n",
    "X2d = jr.permutation(key, X2d)\n",
    "X3d = jr.permutation(key, X3d)\n",
    "Xstatic = jr.permutation(key, Xstatic)\n",
    "Y = jr.permutation(key, Y)\n",
    "\n",
    "# look at ERA5 rain\n",
    "Y = Y[:,0:1]  \n",
    "\n",
    "# remove any entries with nan\n",
    "X3d_nan_idx = jnp.isnan(X3d).any(axis=1).any(axis=1)\n",
    "X2d_nan_idx = jnp.isnan(X2d).any(axis=1)\n",
    "Xstatic_nan_idx = jnp.isnan(Xstatic).any(axis=1)\n",
    "Y_nan_idx = jnp.isnan(Y).any(axis=1)\n",
    "any_nan = X3d_nan_idx | X2d_nan_idx | Y_nan_idx | Xstatic_nan_idx\n",
    "no_nan = ~ any_nan\n",
    "print(f\"Removed {any_nan.sum()} entries with nan\")\n",
    "X2d = X2d[no_nan,:]\n",
    "X3d = X3d[no_nan,:,:]\n",
    "Xstatic = Xstatic[no_nan,:]\n",
    "Y = Y[no_nan,:]\n",
    "\n",
    "\n",
    "# just keep the \"prognostic\" 3d inputs that joe considered (for now)\n",
    "# RH, tehta_e^+, theta_e, theta_e^*\n",
    "names_3d =  [\"RH\", \"tehta_e+\", \"theta_e\", \"theta_e*\"]\n",
    "idx_3d = [1, 9, 7, 8 ]\n",
    "X3d = X3d[:,idx_3d,:]\n",
    "\n",
    "\n",
    "# # also use his \"normalisatopm\" for sigma_o\n",
    "sigma_o = jnp.where(Xstatic[:,0]<0.5, 0.0, 1.0+jnp.log(1+Xstatic[:,2]))\n",
    "Xstatic = Xstatic.at[:,2].set(sigma_o)\n",
    "idx_static = [2]\n",
    "Xstatic = Xstatic[:,idx_static]\n",
    "\n",
    "\n",
    "# no 2d for now\n",
    "idx_2d = []\n",
    "X2d = X2d[:,idx_2d]\n",
    "\n",
    "\n",
    "#remove all pressure levels below 500 hPA\n",
    "lowest_idx = 7 # 11\n",
    "print(f\"Removed all pressure levels below {pressure[:,lowest_idx]} hPa\")\n",
    "X3d = X3d[:, :, lowest_idx:]\n",
    "pressure_levels = pressure[:,lowest_idx:]\n",
    "\n",
    "# # remove no rain days\n",
    "# print(f\"Removed {(Y[:,0]==0).sum()} entries with zero rain\")\n",
    "# X3d = X3d[Y[:,0]>0,:]\n",
    "# X2d = X2d[Y[:,0]>0,:]\n",
    "# Xstatic = Xstatic[Y[:,0]>0,:]\n",
    "# Y = Y[Y[:,0]>0,:]\n",
    "\n",
    "\n",
    "# also log Y\n",
    "print(f\"Applied log transform to Y\")\n",
    "Y = jnp.log(Y+1e-12)\n",
    "print(f\"then standardized Y\")\n",
    "Y_mean = jnp.mean(Y)\n",
    "Y_std = jnp.std(Y)\n",
    "Y = (Y - Y_mean) / Y_std\n",
    "\n",
    "# standardize inputs\n",
    "X3d_std = jnp.std(X3d, axis=0)\n",
    "X3d_mean = jnp.mean(X3d,axis=0)\n",
    "X3d = (X3d - X3d_mean) / X3d_std\n",
    "X2d_std = jnp.std(X2d, axis=0)\n",
    "X2d_mean = jnp.mean(X2d,axis=0)\n",
    "X2d = (X2d - X2d_mean) / X2d_std\n",
    "Xstatic_std = jnp.std(Xstatic, axis=0)\n",
    "Xstatic_mean = jnp.mean(Xstatic,axis=0)\n",
    "Xstatic = (Xstatic - Xstatic_mean) / Xstatic_std\n",
    "\n",
    "\n",
    "# look at all data but 1_000 test\n",
    "\n",
    "N_test = 100\n",
    "N_train = len(X2d) - N_test \n",
    "print(f\"Using {N_train} training and {N_test} testing points!\")\n",
    "num_2d_variables= X2d.shape[1]\n",
    "num_3d_variables= X3d.shape[1]\n",
    "num_static_variables= Xstatic.shape[1]\n",
    "num_not_3d_variables = num_2d_variables + num_static_variables\n",
    "num_variables = num_2d_variables + num_3d_variables + num_static_variables\n",
    "print(f\"using {num_static_variables} static variables\")\n",
    "print(f\"using {num_2d_variables} 2d variables\")\n",
    "print(f\"using {num_3d_variables} 3d variables\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VerticalSmoother(gpx.base.Module):\n",
    "    smoother_mean: Float[Array, \"1 D\"]  = param_field(None)\n",
    "    smoother_input_scale: Float[Array, \"1 D\"] = param_field(None, bijector=tfb.Softplus(low=jnp.array(1.0e-5, dtype=jnp.float64)))\n",
    "    Z_levels: Float[Array, \"1 L\"] = static_field(pressure_levels)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.Z_mean = jnp.mean(self.Z_levels)\n",
    "        self.Z_std = jnp.std(self.Z_levels)\n",
    "        self.Z_levels = (self.Z_levels - self.Z_mean) / self.Z_std\n",
    "\n",
    "    def __call__(self,X3d: Num[Array, \"N D L\"]) -> Num[Array, \"N D\"]:\n",
    "        smoothing_weights = jnp.exp(-0.5*((self.Z_levels-self.smoother_mean.T)/(self.smoother_input_scale.T))**2) # [D, L]\n",
    "        smoothing_weights = (smoothing_weights/ jnp.sum(smoothing_weights, axis=-1, keepdims=True)) # [D, L]\n",
    "        return jnp.sum(jnp.multiply(smoothing_weights , X3d), axis=-1) # [N, D]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CustomDataset(Pytree):\n",
    "\n",
    "    X2d: Num[Array, \"N D\"] = None\n",
    "    X3d: Num[Array, \"N D L\"] = None\n",
    "    Xstatic: Num[Array, \"N D\"] = None\n",
    "    y: Num[Array, \"N Q\"] = None\n",
    "    smoother: VerticalSmoother = None\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        X_temp = self.prep_X(self.X2d, self.X3d, self.Xstatic)\n",
    "        gpx.dataset._check_shape(X_temp, self.y)\n",
    "        gpx.dataset._check_precision(X_temp, self.y)\n",
    "\n",
    "    @property\n",
    "    def n(self) -> int:\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    @property\n",
    "    def in_dim(self) -> int:\n",
    "        return self.X.shape[1]\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.prep_X(self.X2d, self.X3d, self.Xstatic)\n",
    "\n",
    "    def prep_X(self, X2d: Num[Array, \"N D\"], X3d: Num[Array, \"N D L\"], Xstatic: Num[Array, \"N D\"]):\n",
    "        X3d_to_2d = self.smoother(X3d) # [N, D]\n",
    "        return jnp.hstack((X3d_to_2d, X2d, Xstatic)) # always use 3d inputs first\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VerticallyIntegratedRBF(RBF):\n",
    "    smoother: VerticalSmoother = None\n",
    "    \n",
    "\n",
    "def prep_kernel(num_variables: int, num_3d_variables, Y, bij_lengthscale:bool = True):\n",
    "    lengthscale_bij = tfb.SoftClip(jnp.array(1e-2, dtype=jnp.float64),jnp.array(1e2, dtype=jnp.float64))\n",
    "    smoother = VerticalSmoother(jnp.array([[0.0]*num_3d_variables]), jnp.array([[1.0]*num_3d_variables]))\n",
    "    base_kernel = VerticallyIntegratedRBF(lengthscale=jnp.array([1.0]*num_variables), variance = jnp.var(Y), smoother = smoother)\n",
    "    if bij_lengthscale:\n",
    "        base_kernel = base_kernel.replace_bijector( lengthscale = lengthscale_bij)\n",
    "    return base_kernel\n",
    "\n",
    "\n",
    "def plot_params(model, title=None):\n",
    "    if isinstance(model, gpx.variational_families.AbstractVariationalFamily):\n",
    "        model = model.posterior\n",
    "    plt.figure()\n",
    "    opt_3d_kernel =model.prior.kernel\n",
    "    lengthscales = opt_3d_kernel.lengthscale\n",
    "    smoother = model.prior.kernel.smoother\n",
    "    #smoothing_weights = opt_3d_kernel.smoother_bias.T + (1 / (jnp.sqrt(2*math.pi)*opt_3d_kernel.smoother_input_scale.T))*jnp.exp(-0.5*(opt_3d_kernel.Z_levels-opt_3d_kernel.smoother_mean.T)**2/(opt_3d_kernel.smoother_input_scale).T) # [4, 21]\n",
    "    #smoothing_weights = (jnp.exp(-0.5*((opt_3d_kernel.Z_levels-opt_3d_kernel.smoother_mean.T)/(opt_3d_kernel.smoother_input_scale.T))**2)) # [4, 21]\n",
    "    smoothing_weights =  jnp.exp(-0.5*((smoother.Z_levels-smoother.smoother_mean.T)/(smoother.smoother_input_scale.T))**2) # [4, 21]\n",
    "    smoothing_weights = (smoothing_weights/ jnp.sum(smoothing_weights, axis=-1, keepdims=True)) # [4, 21]\n",
    "    for i in range(num_3d_variables):\n",
    "        plt.plot(smoothing_weights[i,:].T,pressure_levels[0,:], label=f\"{names_3d[i]} with lengthscales {lengthscales[i]:.2f}\")\n",
    "    plt.legend()\n",
    "    plt.title(title+f\"other lengthscales are {lengthscales[num_3d_variables:]}\")\n",
    "    plt.gca().invert_yaxis()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f4f8f18ca04f1b8e60d8cb2ef554e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TracerBoolConversionError",
     "evalue": "Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function _body_fun at /home/henry/Documents/python_dev/GPJax/gpjax/scan.py:136 for scan. This value became a tracer due to JAX operations on these lines:\n\n  operation a\u001b[35m:bool[]\u001b[39m = eq b c\n    from line <string>:4 (__eq__)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/henry/Documents/python_dev/GPJax/Play.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m objective \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mjit(gpx\u001b[39m.\u001b[39mobjectives\u001b[39m.\u001b[39mConjugateMLL(negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#objective = jax.jit(gpx.objectives.NonConjugateMLL(negative=True))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m opt_posterior, history \u001b[39m=\u001b[39m gpx\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     model\u001b[39m=\u001b[39;49mposterior,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     objective\u001b[39m=\u001b[39;49mobjective,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     train_data\u001b[39m=\u001b[39;49mD_small,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     optim\u001b[39m=\u001b[39;49mox\u001b[39m.\u001b[39;49madamw(learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-1\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     num_iters\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     key\u001b[39m=\u001b[39;49mjr\u001b[39m.\u001b[39;49mPRNGKey(\u001b[39m42\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     safe\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/Documents/python_dev/GPJax/Play.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m plot_params(opt_posterior,D_small,  title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minitial fit with small data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/python_dev/GPJax/gpjax/fit.py:172\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, objective, train_data, optim, key, num_iters, batch_size, log_rate, verbose, unroll, safe)\u001b[0m\n\u001b[1;32m    169\u001b[0m scan \u001b[39m=\u001b[39m vscan \u001b[39mif\u001b[39;00m verbose \u001b[39melse\u001b[39;00m jax\u001b[39m.\u001b[39mlax\u001b[39m.\u001b[39mscan\n\u001b[1;32m    171\u001b[0m \u001b[39m# Optimisation loop.\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m (model, _), history \u001b[39m=\u001b[39m scan(step, (model, state), (iter_keys), unroll\u001b[39m=\u001b[39;49munroll)\n\u001b[1;32m    174\u001b[0m \u001b[39m# Constrained space.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconstrain()\n",
      "File \u001b[0;32m~/Documents/python_dev/GPJax/gpjax/scan.py:165\u001b[0m, in \u001b[0;36mvscan\u001b[0;34m(f, init, xs, length, reverse, unroll, log_rate, log_value)\u001b[0m\n\u001b[1;32m    161\u001b[0m     _callback(_is_last, _close_tqdm, (y, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m carry, y\n\u001b[0;32m--> 165\u001b[0m carry, ys \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mlax\u001b[39m.\u001b[39;49mscan(\n\u001b[1;32m    166\u001b[0m     _body_fun,\n\u001b[1;32m    167\u001b[0m     init,\n\u001b[1;32m    168\u001b[0m     (_iter_nums, xs),\n\u001b[1;32m    169\u001b[0m     length\u001b[39m=\u001b[39;49mlength,\n\u001b[1;32m    170\u001b[0m     reverse\u001b[39m=\u001b[39;49mreverse,\n\u001b[1;32m    171\u001b[0m     unroll\u001b[39m=\u001b[39;49munroll,\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[39mreturn\u001b[39;00m carry, ys\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_dev/GPJax/gpjax/scan.py:141\u001b[0m, in \u001b[0;36mvscan.<locals>._body_fun\u001b[0;34m(carry, iter_num_and_x)\u001b[0m\n\u001b[1;32m    138\u001b[0m iter_num, x \u001b[39m=\u001b[39m iter_num_and_x\n\u001b[1;32m    140\u001b[0m \u001b[39m# Compute body function.\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m carry, y \u001b[39m=\u001b[39m f(carry, x)\n\u001b[1;32m    143\u001b[0m \u001b[39m# Conditions for iteration number.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m _is_first: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m iter_num \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/python_dev/GPJax/gpjax/fit.py:161\u001b[0m, in \u001b[0;36mfit.<locals>.step\u001b[0;34m(carry, key)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     batch \u001b[39m=\u001b[39m train_data\n\u001b[0;32m--> 161\u001b[0m loss_val, loss_gradient \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvalue_and_grad(loss)(model, batch)\n\u001b[1;32m    162\u001b[0m updates, opt_state \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mupdate(loss_gradient, opt_state, model)\n\u001b[1;32m    163\u001b[0m model \u001b[39m=\u001b[39m ox\u001b[39m.\u001b[39mapply_updates(model, updates)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_dev/GPJax/gpjax/fit.py:141\u001b[0m, in \u001b[0;36mfit.<locals>.loss\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(model: Module, batch: Dataset) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ScalarFloat:\n\u001b[1;32m    140\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mstop_gradient()\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m objective(model\u001b[39m.\u001b[39;49mconstrain(), batch)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpjax/lib/python3.10/weakref.py:509\u001b[0m, in \u001b[0;36mWeakKeyDictionary.setdefault\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetdefault\u001b[39m(\u001b[39mself\u001b[39m, key, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49msetdefault(ref(key, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remove),default)\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpjax/lib/python3.10/site-packages/jax/_src/core.py:1443\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror\u001b[39m(\u001b[39mself\u001b[39m, arg):\n\u001b[0;32m-> 1443\u001b[0m   \u001b[39mraise\u001b[39;00m TracerBoolConversionError(arg)\n",
      "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function _body_fun at /home/henry/Documents/python_dev/GPJax/gpjax/scan.py:136 for scan. This value became a tracer due to JAX operations on these lines:\n\n  operation a\u001b[35m:bool[]\u001b[39m = eq b c\n    from line <string>:4 (__eq__)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class VerticallyIntegratedRBF(VerticallyIntegratedRBF):\n",
    "    dummy: AbstractKernel = gpx.kernels.RBF()\n",
    "\n",
    "# prep fancy kernel for model\n",
    "# first fit with small data to get init for SVGP\n",
    "\n",
    "num_data_for_init=100\n",
    "\n",
    "kernel = prep_kernel(num_variables, num_3d_variables, Y[:num_data_for_init,:])\n",
    "D_small = CustomDataset(\n",
    "    X2d = X2d[:num_data_for_init,:], \n",
    "    X3d = X3d[:num_data_for_init,:], \n",
    "    Xstatic = Xstatic[:num_data_for_init,:], \n",
    "    y = Y[:num_data_for_init,:],\n",
    "    smoother = kernel.smoother,\n",
    ")\n",
    "\n",
    "\n",
    "prior = gpx.gps.Prior(mean_function= gpx.mean_functions.Zero(), kernel = kernel)\n",
    "likelihood = gpx.likelihoods.Gaussian(num_datapoints=D_small.n)\n",
    "posterior = prior * likelihood\n",
    "objective = jax.jit(gpx.objectives.ConjugateMLL(negative=True))\n",
    "#objective = jax.jit(gpx.objectives.NonConjugateMLL(negative=True))\n",
    "opt_posterior, history = gpx.fit(\n",
    "    model=posterior,\n",
    "    objective=objective,\n",
    "    train_data=D_small,\n",
    "    optim=ox.adamw(learning_rate=1e-1),\n",
    "    num_iters=100,\n",
    "    key=jr.PRNGKey(42),\n",
    "    safe=False,\n",
    ")\n",
    "plt.plot(history)\n",
    "plot_params(opt_posterior,D_small,  title=\"initial fit with small data\")\n",
    "\n",
    "\n",
    "\n",
    "# # choose inducing inputs and init SVGP\n",
    "# num_inducing = 100\n",
    "# z = jr.normal(key, (num_inducing , D.X.shape[-1])) # allow this\n",
    "\n",
    "\n",
    "# init_posterior_at_inducing = opt_posterior.predict(z, D_small)\n",
    "# # todo try whitening ?\n",
    "# q = gpx.variational_families.VariationalGaussian(\n",
    "#     posterior=opt_posterior, \n",
    "#     inducing_inputs=z,\n",
    "#     variational_mean= init_posterior_at_inducing.mean()[:,None],\n",
    "#     variational_root_covariance= jnp.linalg.cholesky(init_posterior_at_inducing.covariance() + 1e-5 * jnp.eye(num_inducing)), # todo check this is right!\n",
    "# )\n",
    "\n",
    "# #q = q.replace_trainable(inducing_inputs=False)\n",
    "# # q = q.replace_trainable(variational_mean=False)\n",
    "# # q = q.replace_trainable(variational_root_covariance=False)\n",
    "\n",
    "# objective = jax.jit(gpx.objectives.ELBO(negative=True))\n",
    "\n",
    "\n",
    "# def zero_grads():\n",
    "#     def init_fn(_): \n",
    "#         return ()\n",
    "#     def update_fn(updates, state, params=None):\n",
    "#         return jax.tree_map(jnp.zeros_like, updates), ()\n",
    "#     return ox.GradientTransformation(init_fn, update_fn)\n",
    "\n",
    "# optim_pytree = q.replace(\n",
    "#     posterior = zero_grads(), \n",
    "#     variational_mean = ox.adamw(1e-2),\n",
    "#     variational_root_covariance = ox.adamw(1e-2), \n",
    "#     inducing_inputs= ox.adamw(1e-2),\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# optim = optim_builder(optim_pytree)\n",
    "\n",
    "# opt_q, history = gpx.fit(\n",
    "#     model=q,\n",
    "#     objective=objective,\n",
    "#     train_data=D,\n",
    "#     optim=optim,\n",
    "#     num_iters=500,\n",
    "#     key=jr.PRNGKey(42),\n",
    "#     batch_size=512,\n",
    "# )\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(history)\n",
    "# plot_params(opt_q,D,  title=\"full fit\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
